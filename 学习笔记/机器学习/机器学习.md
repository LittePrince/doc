# 1. 机器学习

## 1.1 有监督学习

训练的标签是已知的，而预测的标签是未知的。

| 特征1~n | 标签 |      |
| ------- | ---- | ---- |
| 已知    | 已知 | 训练 |
| 已知    | 求解 | 预测 |

## 1.2 无监督学习

训练的标签是未知的，预测的标签是未知的。

| 特征1~n | 标签 |      |
| ------- | ---- | ---- |
| 已知    |      |      |
|         |      |      |
|         |      |      |



## 1.3 半监督学习

训练的标签一半是已知一半是未知。

# 2. 概率与统计

## 2.1 概率

概率是已知整体求具体事件的概率

## 2.2 统计

已知事件的发生，而求整体的信息。

## 2.3 重要的统计量

- 期望
- 方差
- 协方差（十分重要）、相关系数
- 矩（较为不重要）

### 2.3.1 期望

-  离散型

$E(X)=\sum^{}_{}x_ip_i $

- 连续型

$E(x)=\displaystyle \int^{\infty}_{-\infty}{xf(x)dx}$ 

#### 2.3.2 期望的性质

![1569423430629](.\img\1569423430629.png)

#### 2.3.3 独立于不相关的区别

1、描述对象不同

独立描述的对象是事件，涉及的是A，B是两事件；不相关描述的对象是随机变量，涉及的是随机变量 X 和 Y 。

2、判断条件不同

独立的判断条件是概率，如果满足等式 p(AB)=P(A)P(B)，则事件[相互独立](https://www.baidu.com/s?wd=%E7%9B%B8%E4%BA%92%E7%8B%AC%E7%AB%8B&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)；不相关的判断条件是相关系数，如果随机变量 X 和 Y 的相关系数为0，则X和Y 不相关。

**扩展资料：**

概率论中的不相关是指两个随机变量线性不相关，换言之，可能存在其他的关系；而独立是指两个随机变量之间没有任何一点关系。也就是说，独立一定不相关，而不相关不一定独立。

两个变量是不是相关变量需要用相关系数r来判定，相关系数是用以反映变量之间相关关系密切程度的统计指标。相关系数是按积差方法计算，同样以两变量与各自平均值的离差为基础，通过两个离差相乘来反映两变量之间相关程度。

若n(n≥2)个随机变量[相互独立](https://www.baidu.com/s?wd=%E7%9B%B8%E4%BA%92%E7%8B%AC%E7%AB%8B&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)，则其中任意m(2≤m≤n)个随机变量也[相互独立](https://www.baidu.com/s?wd=%E7%9B%B8%E4%BA%92%E7%8B%AC%E7%AB%8B&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)，与各随机变量相联系的任意n个事件也相互独立。

### 2.4方差

描述的是：（（随机变量偏离于你的期望）的差距的平方）的统计意义的平均值

![1569424121184](C:.\img\1569424121184.png)

### 2.5 协方差

定义：表示两个分布平均偏离期望的

![1569424631581](.\img\1569424631581.png)

协方差性质

![1569424781039](.\img\1569424781039.png)

TODO (2)数理统计与参数估计.avi 50.28

# 概率论与机器学习的关系

特征1~分布X1

... 	...

特征n~分布Xn

标签~分布Y

- 统计估计的是总体的分布，机器学习训练出来的是模型，而模型可能包含了很多分布。
- 训练与预测过程是一个核心的评价指标就是模型的误差
- 误差本身可以是概率的形式，与概率密切相关
- 对误差的不同定义方式就演化成了不同损失函数的定义方式
- 机器学习是概率与统计的进阶版本（不严谨的说法）